---
title: "Data_exploration"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Data_exploration}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(HMMNLP)
```

## Train and test set splitting

```{r}
words <- Penn_TreeBank$words
tags <- Penn_TreeBank$tags


train_words <- words[1:floor(0.8*length(words))]
train_tags <- tags[1:floor(0.8*length(words))]
test_words <- words[-c(1:floor(0.8*length(words)))]
test_tags <- tags[-c(1:floor(0.8*length(words)))]

```

## Visualize the first 10 sample in the trainset

```{r}
print(train_words[1:10])
print(train_tags[1:10])
```


## calculate the tag transition count matrix

```{r}
tags_level = unique(tags)
# Initialize the transition count matrix
tag_tcm = matrix(data=0,nrow = length(tags_level), ncol = length(tags_level))
for(i in 1:(length(train_tags)-1)){
  idx_current = which(tags_level==train_tags[i])
  idx_next = which(tags_level==train_tags[i+1])
  tag_tcm[idx_current,idx_next] = 1+tag_tcm[idx_current,idx_next]
}
tag_tcm
```

## calculate the word emission count matrix

```{r}
#get_dictionary <-function(words){
  dictionary = unique(words)
  return(dictionary)
}

dictionary = get_dictionary(words)
word_ecm = matrix(data=0, nrow=length(tags_level), ncol = length(dictionary))
for(i in 1:length(train_tags)){
  idx_tag = which(tags_level==train_tags[i])
  idx_word = which(dictionary==train_words[i])
  word_ecm[idx_tag,idx_word] = word_ecm[idx_tag,idx_word]+1
}
```

```{r}
barplot(rowSums(word_ecm),names.arg = tags_level,main = "Prevelency among tags")
```

## compute the transition matrix

$$P(t_i|t_{i-1}) = \frac{c(t_{i-1},t_i)+\alpha}{c(t_{i-1})+\alpha\cdot N}$$

```{r}
#create_transition_matrix <- function(tcm,alpha){
  N = ncol(tcm)
  # Divide each row by the corresponding constant
  transition_matrix <- sweep(tcm+alpha, 1, rowSums(tcm)+alpha*N, FUN = "/")
  return(transition_matrix)
}

T = create_transition_matrix(tag_tcm,0.001)
## The transition probability of noun after verb
cat("The transition probability of noun after verb",T[36,21],"\n")
cat("The transition probability of verb after noun",T[21,36])
```

## Compute the emission matrix

```{r}
#create_emission_matrix <- function(ecm,alpha){
#  N = ncol(ecm)
  # Divide each row by the corresponding constant
#  emission_matrix <- sweep(ecm+alpha, 1, rowSums(ecm)+alpha*N, FUN = "/")
#  return(emission_matrix)
#}
E = create_emission_matrix(ecm = word_ecm,alpha = 0.001)
E[,1]
```

## Viterbi Algorithm

```{r}
tag2int <- setNames(seq_along(tags_level), tags_level)
word2int <- setNames(seq_along(dictionary),dictionary)
v= viterbi(train_words[1:10],tags_level = tags_level,trans_p = T,emit_p = E,tag2int, word2int)
v$path
```


## Data preperation, spliting the test data into 765 sentences
```{r}
# Find indices where "." appears
period_indices <- which(test_words == ".")

# Create a sequence of indices to split the array
split_indices <- c(1, period_indices[-length(period_indices)] + 1)

# Split the array based on these indices
split_test_words <- split(test_words, findInterval(seq_along(test_words), c(split_indices, Inf)))

# Remove the periods and empty arrays if needed
split_test_words <- split_test_words[sapply(split_test_words, length) > 0]

# Result
split_test_words[[2]]
```
## Evaluation
```{r}
predicted_tags = c()
for( i in 1:length(split_test_words)){
  pred = viterbi(split_test_words[[i]],tags_level = tags_level,trans_p = T,emit_p = E)
  predicted_tags = c(predicted_tags,pred$path)
}
true_tags = test_tags
evaluation_hmm = evaluate_pos_tagging(predicted_tags,test_tags)

```

```{r}
evaluation_hmm$accuracy
evaluation_hmm$precision
evaluation_hmm$F1
```


## Matrix Visualization

```{r}
# Plot the heatmap of confusion
confussion_heatmap = plot_confusion_matrix_heatmap(evaluation_hmm$confusion_matrix)
print(confussion_heatmap)
```

